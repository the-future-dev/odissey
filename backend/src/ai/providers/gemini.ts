import {
  AIProvider,
  AIModality,
  TextToTextRequest,
  TextToTextResponse,
  AIProviderError,
  UnsupportedModalityError
} from '../interfaces';

export interface GeminiConfig {
  apiKey: string;
  baseUrl?: string;
  model?: string;
}

export class GeminiProvider implements AIProvider {
  readonly name = 'gemini';
  readonly supportedModalities = [AIModality.TextToText];

  private apiKey: string;
  private baseUrl: string;
  private model: string;

  constructor(config: GeminiConfig) {
    this.apiKey = config.apiKey;
    this.baseUrl = config.baseUrl || 'https://generativelanguage.googleapis.com/v1beta';
    this.model = config.model || 'gemini-2.5-flash';
  }

  async generateText(request: TextToTextRequest): Promise<TextToTextResponse> {
    if (!this.supportedModalities.includes(AIModality.TextToText)) {
      throw new UnsupportedModalityError(AIModality.TextToText, this.name);
    }

    try {
      // Extract system message and convert other messages to Gemini format
      const { systemInstruction, contents } = this.formatMessages(request.messages);
      
      const payload: any = {
        contents,
        generationConfig: {
          temperature: request.temperature,
          maxOutputTokens: request.maxTokens,
          ...(request.stopSequences && { stopSequences: request.stopSequences })
        }
      };

      // Add system instruction if present
      if (systemInstruction) {
        payload.systemInstruction = {
          parts: [{ text: systemInstruction }]
        };
      }

      const response = await fetch(
        `${this.baseUrl}/models/${this.model}:generateContent?key=${this.apiKey}`,
        {
          method: 'POST',
          headers: {
            'Content-Type': 'application/json',
          },
          body: JSON.stringify(payload),
        }
      );

      if (!response.ok) {
        const errorText = await response.text();
        console.error('Gemini API Error Response:', errorText);
        throw new AIProviderError(
          `Gemini API error: ${errorText}`,
          this.name,
          response.status
        );
      }

      const data = await response.json() as any;
      console.log('Gemini API Response structure:', JSON.stringify({
        candidatesCount: data.candidates?.length || 0,
        hasContent: !!data.candidates?.[0]?.content,
        finishReason: data.candidates?.[0]?.finishReason
      }));
      
      if (!data.candidates || data.candidates.length === 0) {
        throw new AIProviderError(
          'No response generated by Gemini',
          this.name
        );
      }

      const candidate = data.candidates[0];
      const content = candidate.content?.parts?.[0]?.text || '';

      if (!content.trim()) {
        throw new AIProviderError(
          'Empty response generated by Gemini',
          this.name
        );
      }

      return {
        content: content.trim(),
        usage: data.usageMetadata ? {
          promptTokens: data.usageMetadata.promptTokenCount || 0,
          completionTokens: data.usageMetadata.candidatesTokenCount || 0,
          totalTokens: data.usageMetadata.totalTokenCount || 0
        } : undefined
      };

    } catch (error) {
      if (error instanceof AIProviderError) {
        throw error;
      }
      
      const errorMessage = error instanceof Error ? error.message : String(error);
      console.error('Gemini Provider Error:', errorMessage, error);
      throw new AIProviderError(
        `Failed to generate text: ${errorMessage}`,
        this.name,
        error
      );
    }
  }

  private formatMessages(messages: Array<{ role: string; content: string }>) {
    let systemInstruction: string | null = null;
    const contents: any[] = [];
    
    for (const message of messages) {
      if (message.role === 'system') {
        systemInstruction = message.content;
      } else {
        const role = message.role === 'assistant' ? 'model' : 'user';
        contents.push({
          role,
          parts: [{ text: message.content }]
        });
      }
    }
    
    return { systemInstruction, contents };
  }
} 